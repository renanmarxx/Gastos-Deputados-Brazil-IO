# Initial workflow name
name: Connect to an AWS role from a GitHub repository

# Controls when actions will be executed. Invokes the workflow on push events, but only for the main branch.
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  AWS_REGION: "us-east-1"

permissions:
  id-token: write
  contents: read

jobs:
  AssumeRoleAndCallIdentity:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Branch
        uses: actions/checkout@v3

      - name: Configure AWS Credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: arn:aws:iam::535942231592:role/GitHub_Actions_Personal # altere para a ARN da sua IAM role
          role-session-name: GitHub_to_AWS_via_FederatedOIDC
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Use credentials directly
        run: |
          export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
          export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
          export AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN

          echo "Temporary valid credentials sent to Databricks environment"

      - name: STS GetCallerIdentity
        run: aws sts get-caller-identity

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12.6'
          architecture: 'x64'

      - name: Install Poetry
        run: |
          python -m pip install --upgrade pip
          pip install poetry

      - name: Cache Poetry and pip
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pypoetry
            ~/.cache/pip
          key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
          restore-keys: |
            ${{ runner.os }}-poetry-

      - name: Install dependencies (Poetry)
        run: |
          poetry install --no-interaction --no-ansi --no-root
      
      - name: Activating Poetry Shell (virtual environment)
        run: |
          poetry env activate

      - name: Run black on python files
        run: |
          poetry run black scripts/brasil_io.py

      - name: Generate CSV
        env:
          BRASIL_IO_TOKEN: ${{ secrets.BRASIL_IO_TOKEN }}
        run: |
          poetry run python scripts/brasil_io.py

      - name: Upload to S3 
        run: |
          aws s3 cp data/gastos-deputados_cota_parlamentar.csv.gz ${{ secrets.LANDING_BUCKET_INGESTION }}
      
      ###############################################################
      # ➤ GERAR CREDENCIAIS TEMPORÁRIAS (STS) PARA O DATABRICKS
      ###############################################################
      #- name: Generate temporary AWS STS credentials for Databricks
      #  id: stscreds
      #  run: |
      #    CREDS=$(aws sts get-session-token --duration-seconds 900)
      #    echo "AWS_ACCESS_KEY_ID=$(echo $CREDS | jq -r .Credentials.AccessKeyId)" >> $GITHUB_ENV
      #    echo "AWS_SECRET_ACCESS_KEY=$(echo $CREDS | jq -r .Credentials.SecretAccessKey)" >> $GITHUB_ENV
      #    echo "AWS_SESSION_TOKEN=$(echo $CREDS | jq -r .Credentials.SessionToken)" >> $GITHUB_ENV
      #    echo "AWS_EXPIRATION=$(echo $CREDS | jq -r .Credentials.Expiration)" >> $GITHUB_ENV
          
      ###############################################################
      # ➤ CHAMAR UM JOB NO DATABRICKS E PASSAR AS CREDENCIAIS TEMPORÁRIAS
      ###############################################################
      - name: Trigger Databricks Ingestion Job with STS credentials
        run: |
          curl -X POST "${{ secrets.DATABRICKS_WORKSPACE_URL }}/api/2.1/jobs/run-now" \
            -H "Authorization: Bearer ${{ secrets.DATABRICKS_TOKEN }}" \
            -H "Content-Type: application/json" \
            -d "{
              \"job_id\": \"${{ secrets.DATABRICKS_JOB_ID }}\",
              \"notebook_params\": {
                \"aws_access_key\": \"${AWS_ACCESS_KEY_ID}\",
                \"aws_secret_key\": \"${AWS_SECRET_ACCESS_KEY}\",
                \"aws_session_token\": \"${AWS_SESSION_TOKEN}\"
              }
            }"
          
# Observações 1:
# s3://gastos-deputados-brasil-io/landing-bucket-gastos-deputados-brasil-io/
# s3://renan-marx-data-engineering-projects/gastos-deputados-brasil-io/landing-bucket-gastos-deputados-brasil-io/
